{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\S W I F T\n",
      "[nltk_data]     X\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\S W I F T\n",
      "[nltk_data]     X\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\S W I F T\n",
      "[nltk_data]     X\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\S W I F T\n",
      "[nltk_data]     X\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('indonesian'))\n",
    "    stop_words = stop_words - {'tidak', 'kurang', 'bukan', 'tak', 'belum', 'enggak', 'enggaklah', 'janganlah', 'jangan', 'jgn', 'jgnlah', 'nggak', 'nggaklah', 'ga', 'gak', 'gaklah', 'tdk', 'tdklah', 'taklah', 'kuranglah', 'bukanlah', 'tidaklah'}\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data = pd.read_csv('data/train_preprocess.tsv', sep='\\t', header=None, names=['text', 'label'])\n",
    "valid_data = pd.read_csv('data/valid_preprocess.tsv', sep='\\t', header=None, names=['text', 'label'])\n",
    "test_data = pd.read_csv('data/test_preprocess.tsv', sep='\\t', header=None, names=['text', 'label'])\n",
    "\n",
    "# Preprocess data\n",
    "X_train = train_data['text'].apply(preprocess_text)\n",
    "y_train = train_data['label']\n",
    "\n",
    "X_valid = valid_data['text'].apply(preprocess_text)\n",
    "y_valid = valid_data['label']\n",
    "\n",
    "X_test = test_data['text'].apply(preprocess_text)\n",
    "y_test = test_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Bag of Words\n",
    "vectorizer = CountVectorizer(lowercase=True, ngram_range=(1,2))\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_valid_bow = vectorizer.transform(X_valid)\n",
    "X_test_bow = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8873015873015873\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.89      0.86       394\n",
      "     neutral       0.86      0.64      0.73       131\n",
      "    positive       0.92      0.93      0.93       735\n",
      "\n",
      "    accuracy                           0.89      1260\n",
      "   macro avg       0.87      0.82      0.84      1260\n",
      "weighted avg       0.89      0.89      0.89      1260\n",
      "\n",
      "Test Accuracy: 0.808\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.95      0.86       204\n",
      "     neutral       0.71      0.41      0.52        88\n",
      "    positive       0.87      0.84      0.85       208\n",
      "\n",
      "    accuracy                           0.81       500\n",
      "   macro avg       0.78      0.73      0.74       500\n",
      "weighted avg       0.80      0.81      0.80       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression model\n",
    "lr_model = LogisticRegression(max_iter=200)\n",
    "lr_model.fit(X_train_bow, y_train)\n",
    "\n",
    "y_valid_pred = lr_model.predict(X_valid_bow)\n",
    "print('Validation Accuracy:', accuracy_score(y_valid, y_valid_pred))\n",
    "print('Validation Classification Report:\\n', classification_report(y_valid, y_valid_pred))\n",
    "\n",
    "y_test_pred = lr_model.predict(X_test_bow)\n",
    "print('Test Accuracy:', accuracy_score(y_test, y_test_pred))\n",
    "print('Test Classification Report:\\n', classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8507936507936508\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.81      0.80       394\n",
      "     neutral       0.97      0.47      0.64       131\n",
      "    positive       0.87      0.94      0.90       735\n",
      "\n",
      "    accuracy                           0.85      1260\n",
      "   macro avg       0.88      0.74      0.78      1260\n",
      "weighted avg       0.86      0.85      0.84      1260\n",
      "\n",
      "Test Accuracy: 0.698\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.92      0.78       204\n",
      "     neutral       0.83      0.11      0.20        88\n",
      "    positive       0.72      0.73      0.73       208\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.74      0.59      0.57       500\n",
      "weighted avg       0.72      0.70      0.65       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_bow, y_train)\n",
    "\n",
    "y_valid_pred = nb_model.predict(X_valid_bow)\n",
    "print('Validation Accuracy:', accuracy_score(y_valid, y_valid_pred))\n",
    "print('Validation Classification Report:\\n', classification_report(y_valid, y_valid_pred))\n",
    "\n",
    "y_test_pred = nb_model.predict(X_test_bow)\n",
    "print('Test Accuracy:', accuracy_score(y_test, y_test_pred))\n",
    "print('Test Classification Report:\\n', classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8674603174603175\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.88      0.84       394\n",
      "     neutral       0.78      0.58      0.66       131\n",
      "    positive       0.92      0.91      0.92       735\n",
      "\n",
      "    accuracy                           0.87      1260\n",
      "   macro avg       0.83      0.79      0.81      1260\n",
      "weighted avg       0.87      0.87      0.87      1260\n",
      "\n",
      "Test Accuracy: 0.778\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.90      0.82       204\n",
      "     neutral       0.66      0.38      0.48        88\n",
      "    positive       0.84      0.83      0.83       208\n",
      "\n",
      "    accuracy                           0.78       500\n",
      "   macro avg       0.75      0.70      0.71       500\n",
      "weighted avg       0.77      0.78      0.77       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM model\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train_bow, y_train)\n",
    "\n",
    "y_valid_pred = svm_model.predict(X_valid_bow)\n",
    "print('Validation Accuracy:', accuracy_score(y_valid, y_valid_pred))\n",
    "print('Validation Classification Report:\\n', classification_report(y_valid, y_valid_pred))\n",
    "\n",
    "y_test_pred = svm_model.predict(X_test_bow)\n",
    "print('Test Accuracy:', accuracy_score(y_test, y_test_pred))\n",
    "print('Test Classification Report:\\n', classification_report(y_test, y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
